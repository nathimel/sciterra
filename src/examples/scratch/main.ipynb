{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanielimel/miniforge3/envs/sciterra/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sciterra.atlas import Atlas\n",
    "from sciterra.cartography import Cartographer\n",
    "from sciterra.librarians.s2librarian import SemanticScholarLibrarian\n",
    "from sciterra.librarians.adslibrarian import ADSLibrarian\n",
    "from sciterra.vectorization.scibert import SciBERTVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibtex_fp = \"data/single_publication.bib\"\n",
    "# single_path = \"outputs/atlas_single\"\n",
    "# double_path = \"outputs/atlas_double\"\n",
    "double_path = \"outputs/astro_atlas\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu.\n",
      "Querying Semantic Scholar for 1 total papers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress using call_size=10: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.26it/s]\n"
     ]
    }
   ],
   "source": [
    "crt = Cartographer(\n",
    "    # librarian = SemanticScholarLibrarian(), \n",
    "    librarian = ADSLibrarian(),\n",
    "    vectorizer = SciBERTVectorizer(),\n",
    ")\n",
    "\n",
    "# Construct Atlas\n",
    "atl = crt.bibtex_to_atlas(bibtex_fp)\n",
    "\n",
    "pub = list(atl.publications.values())[0]\n",
    "center = pub.identifier\n",
    "\n",
    "# pub, = crt.librarian.get_publications([\"DOI:10.3765/salt.v1i0.5346\"])#urs truly\n",
    "# center = pub.identifier\n",
    "# atl = Atlas([pub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'46258318d877a145b0b8c9525cb11e7ce5993139': sciterra.publication.Publication:46258318d877a145b0b8c9525cb11e7ce5993139}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atl.publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first expansion\n",
    "# atl_single_exp = Atlas.load(single_path)\n",
    "# atl_single_exp = crt.expand(atl, center=center)\n",
    "# atl_single_exp = crt.project(atl_single_exp)\n",
    "\n",
    "# atl_single_exp.save(single_path)\n",
    "\n",
    "# atl_single_exp_loaded = Atlas.load(single_path)\n",
    "atl_double_exp = Atlas.load(double_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansion will include 1000 new publications.\n",
      "Querying Semantic Scholar for 1000 total papers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x16da60540> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x16da60360> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x1664e8cc0> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cdcc20> 3 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cdcb80> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cdcc20> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cde480> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cde2a0> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cddf80> 4 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had to call <function SemanticScholarLibrarian.get_publications.<locals>.get_papers at 0x165cdfd80> 2 times to get a response.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# second expansion\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# atl_double_exp = crt.expand(atl_single_exp, center=center, n_pubs_max=1000)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m atl_double_exp \u001b[39m=\u001b[39m crt\u001b[39m.\u001b[39;49mexpand(atl_double_exp, center\u001b[39m=\u001b[39;49mcenter, n_pubs_max\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/uci/projects/sciterra/src/sciterra/cartography.py:216\u001b[0m, in \u001b[0;36mCartographer.expand\u001b[0;34m(self, atl, center, n_pubs_max, n_sources_max)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpansion will include \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ids)\u001b[39m}\u001b[39;00m\u001b[39m new publications.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[39m# Retrieve publications from ids using a librarian\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m new_publications \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrarian\u001b[39m.\u001b[39;49mget_publications(ids)\n\u001b[1;32m    218\u001b[0m \u001b[39m# New atlas\u001b[39;00m\n\u001b[1;32m    219\u001b[0m atl_exp \u001b[39m=\u001b[39m Atlas(new_publications)\n",
      "File \u001b[0;32m~/uci/projects/sciterra/src/sciterra/librarians/s2librarian.py:171\u001b[0m, in \u001b[0;36mSemanticScholarLibrarian.get_publications\u001b[0;34m(self, paper_ids, call_size, n_attempts_per_query, convert, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             result \u001b[39m=\u001b[39m [\n\u001b[1;32m    163\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_paper(\n\u001b[1;32m    164\u001b[0m                     paper_id\u001b[39m=\u001b[39mpaper_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[39mfor\u001b[39;00m paper_id \u001b[39min\u001b[39;00m ids\n\u001b[1;32m    168\u001b[0m             ]\n\u001b[1;32m    169\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m--> 171\u001b[0m     papers\u001b[39m.\u001b[39mextend(get_papers())\n\u001b[1;32m    172\u001b[0m     pbar\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(ids))\n\u001b[1;32m    173\u001b[0m pbar\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/uci/projects/sciterra/src/sciterra/misc/utils.py:87\u001b[0m, in \u001b[0;36mkeep_trying.<locals>._keep_trying.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     84\u001b[0m     \u001b[39m# Loop over for n-1 attempts, trying to return\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_attempts \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     86\u001b[0m         \u001b[39m# waiting may help with connection errors?\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         time\u001b[39m.\u001b[39msleep(sleep_after_attempt)\n\u001b[1;32m     89\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m             result \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# second expansion\n",
    "# atl_double_exp = crt.expand(atl_single_exp, center=center, n_pubs_max=1000)\n",
    "\n",
    "atl_double_exp = crt.expand(atl_double_exp, center=center, n_pubs_max=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(atl_double_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_double_exp = crt.project(atl_double_exp)\n",
    "\n",
    "atl_double_exp.save(double_path)\n",
    "\n",
    "# atl_double_exp_loaded = Atlas.load(double_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_double_exp_loaded = Atlas.load(double_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "identifier = random.choice(atl_double_exp.projection.index_to_identifier)\n",
    "pub = atl_double_exp[identifier]\n",
    "pub.abstract"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciterra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
