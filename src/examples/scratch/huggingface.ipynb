{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook for Integrating with Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import huggingface_hub as hfhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sciterra import Atlas\n",
    "from sciterra import Cartographer\n",
    "from sciterra.librarians import SemanticScholarLibrarian # or ADSLibrarian\n",
    "from sciterra.vectorization import SciBERTVectorizer # among others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "atlas_dirpath = \"../atlas\"\n",
    "# model = \"Falconsai/text_summarization\"\n",
    "model = \"liminerity/Phigments12\"\n",
    "n_summarized = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sciterra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl = Atlas.load(atlas_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cartographer with a Semantic Scholar librarian and a SciBERT vectorizer\n",
    "crt = Cartographer(\n",
    "    librarian=SemanticScholarLibrarian(),\n",
    "    vectorizer=SciBERTVectorizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HFHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "token = hfhub.get_token()\n",
    "if token is None:\n",
    "    hfhub.login()\n",
    "    token = hfhub.get_token()\n",
    "\n",
    "# Format for Inference API\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(payload):\n",
    "\n",
    "\tapi_url = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "\tresponse = requests.post(api_url, headers=headers, json=payload)\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the publications most-similar to the original\n",
    "sorted_keys, sorted_values = crt.sort(atl, center=atl.center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the abstracts for the most-similar publications\n",
    "combined_abstracts = \"Please summarize the following abstracts:\"\n",
    "for i, identifier in enumerate(sorted_keys[:n_summarized]):\n",
    "\n",
    "    combined_abstracts += f\"This is the {i}th abstract:\\n\"\n",
    "    combined_abstracts += atl.publications[identifier].abstract\n",
    "    combined_abstracts += \"\\n\"\n",
    "\n",
    "print(combined_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the abstracts for the most-similar publications\n",
    "combined_abstracts = \"\"\n",
    "for i, identifier in enumerate(sorted_keys[:n_summarized]):\n",
    "\n",
    "    combined_abstracts += '\\n\\n' + atl.publications[identifier].abstract\n",
    "\n",
    "print(combined_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query({\"input\": combined_abstracts})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "eval_module = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_module.compute(predictions=[prediction,], references=[combined_abstracts,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
